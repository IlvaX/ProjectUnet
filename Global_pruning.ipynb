{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IlvaX/ProjectUnet/blob/main/Global_pruning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Referece: https://pytorch.org/tutorials/intermediate/pruning_tutorial.html"
      ],
      "metadata": {
        "id": "BxfvdTinl9c1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYF7IDixbCKh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.utils.prune as prune\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import normalize\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.optimizers import Adam\n",
        "import glob\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "jrWMvhmUd1eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder_conv1 = nn.Conv2d(1, 64, 3, padding=1)\n",
        "        self.encoder_bn1 = nn.BatchNorm2d(64)\n",
        "        self.encoder_relu1 = nn.ReLU(inplace=True)\n",
        "        self.encoder_pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.encoder_conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.encoder_bn2 = nn.BatchNorm2d(128)\n",
        "        self.encoder_relu2 = nn.ReLU(inplace=True)\n",
        "        self.encoder_pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.encoder_conv3 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.encoder_bn3 = nn.BatchNorm2d(256)\n",
        "        self.encoder_relu3 = nn.ReLU(inplace=True)\n",
        "        self.encoder_pool3 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Bridge\n",
        "        self.bridge_conv = nn.Conv2d(256, 512, 3, padding=1)\n",
        "        self.bridge_bn = nn.BatchNorm2d(512)\n",
        "        self.bridge_relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder_upsample1 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        self.decoder_conv1 = nn.Conv2d(512, 256, 3, padding=1)\n",
        "        self.decoder_bn1 = nn.BatchNorm2d(256)\n",
        "        self.decoder_relu1 = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.decoder_upsample2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        self.decoder_conv2 = nn.Conv2d(256, 128, 3, padding=1)\n",
        "        self.decoder_bn2 = nn.BatchNorm2d(128)\n",
        "        self.decoder_relu2 = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.decoder_upsample3 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        self.decoder_conv3 = nn.Conv2d(128, 64, 3, padding=1)\n",
        "        self.decoder_bn3 = nn.BatchNorm2d(64)\n",
        "        self.decoder_relu3 = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.output_conv = nn.Conv2d(64, 10, 1)\n",
        "        self.output_softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        enc1 = self.encoder_relu1(self.encoder_bn1(self.encoder_conv1(x)))\n",
        "        enc1_pool = self.encoder_pool1(enc1)\n",
        "\n",
        "        enc2 = self.encoder_relu2(self.encoder_bn2(self.encoder_conv2(enc1_pool)))\n",
        "        enc2_pool = self.encoder_pool2(enc2)\n",
        "\n",
        "        enc3 = self.encoder_relu3(self.encoder_bn3(self.encoder_conv3(enc2_pool)))\n",
        "        enc3_pool = self.encoder_pool3(enc3)\n",
        "\n",
        "        # Bridge\n",
        "        bridge = self.bridge_relu(self.bridge_bn(self.bridge_conv(enc3_pool)))\n",
        "\n",
        "        # Decoder\n",
        "        dec1 = self.decoder_relu1(self.decoder_bn1(self.decoder_conv1(self.decoder_upsample1(bridge))))\n",
        "        dec1_concat = torch.cat((dec1, enc3), dim=1)\n",
        "\n",
        "        dec2 = self.decoder_relu2(self.decoder_bn2(self.decoder_conv2(self.decoder_upsample2(dec1_concat))))\n",
        "        dec2_concat = torch.cat((dec2, enc2), dim=1)\n",
        "\n",
        "        dec3 = self.decoder_relu3(self.decoder_bn3(self.decoder_conv3(self.decoder_upsample3(dec2_concat))))\n",
        "        dec3_concat = torch.cat((dec3, enc1), dim=1)\n",
        "\n",
        "        # Output\n",
        "        output = self.output_conv(dec3_concat)\n",
        "        output = self.output_softmax(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "model = UNet().to(device=device)\n"
      ],
      "metadata": {
        "id": "FZ0ijsa9bNQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prune.random_unstructured(module, name=\"weight\", amount=0.3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2A4ZvhwiBOV",
        "outputId": "2e9c3205-4dd3-4b2e-998d-e0250ec83e17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = UNet()\n",
        "\n",
        "# Define the parameters to prune\n",
        "parameters_to_prune = (\n",
        "    (model.encoder_conv1, 'weight'),\n",
        "    (model.encoder_conv2, 'weight'),\n",
        "    (model.encoder_conv3, 'weight'),\n",
        "    (model.bridge_conv, 'weight'),\n",
        "    (model.decoder_conv1, 'weight'),\n",
        "    (model.decoder_conv2, 'weight'),\n",
        "    (model.decoder_conv3, 'weight'),\n",
        "    (model.output_conv, 'weight'),\n",
        ")\n",
        "\n",
        "prune.global_unstructured(\n",
        "    parameters_to_prune,\n",
        "    pruning_method=prune.L1Unstructured,\n",
        "    amount=0.2,\n",
        ")"
      ],
      "metadata": {
        "id": "WUYNZE9Wj3eU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\n",
        "    \"Sparsity in encoder_conv1.weight: {:.2f}%\".format(\n",
        "        100. * float(torch.sum(model.encoder_conv1.weight == 0))\n",
        "        / float(model.encoder_conv1.weight.nelement())\n",
        "    )\n",
        ")\n",
        "print(\n",
        "    \"Sparsity in encoder_conv2.weight: {:.2f}%\".format(\n",
        "        100. * float(torch.sum(model.encoder_conv2.weight == 0))\n",
        "        / float(model.encoder_conv2.weight.nelement())\n",
        "    )\n",
        ")\n",
        "print(\n",
        "    \"Sparsity in encoder_conv3.weight: {:.2f}%\".format(\n",
        "        100. * float(torch.sum(model.encoder_conv3.weight == 0))\n",
        "        / float(model.encoder_conv3.weight.nelement())\n",
        "    )\n",
        ")\n",
        "print(\n",
        "    \"Sparsity in bridge_conv.weight: {:.2f}%\".format(\n",
        "        100. * float(torch.sum(model.bridge_conv.weight == 0))\n",
        "        / float(model.bridge_conv.weight.nelement())\n",
        "    )\n",
        ")\n",
        "print(\n",
        "    \"Sparsity in decoder_conv1.weight: {:.2f}%\".format(\n",
        "        100. * float(torch.sum(model.decoder_conv1.weight == 0))\n",
        "        / float(model.decoder_conv1.weight.nelement())\n",
        "    )\n",
        ")\n",
        "print(\n",
        "    \"Sparsity in decoder_conv2.weight: {:.2f}%\".format(\n",
        "        100. * float(torch.sum(model.decoder_conv2.weight == 0))\n",
        "        / float(model.decoder_conv2.weight.nelement())\n",
        "    )\n",
        ")\n",
        "print(\n",
        "    \"Sparsity in decoder_conv3.weight: {:.2f}%\".format(\n",
        "        100. * float(torch.sum(model.decoder_conv3.weight == 0))\n",
        "        / float(model.decoder_conv3.weight.nelement())\n",
        "    )\n",
        ")\n",
        "print(\n",
        "    \"Sparsity in fc3.weight: {:.2f}%\".format(\n",
        "        100. * float(torch.sum(model.output_conv.weight == 0))\n",
        "        / float(model.output_conv.weight.nelement())\n",
        "    )\n",
        ")\n",
        "print(\n",
        "    \"Global sparsity: {:.2f}%\".format(\n",
        "        100. * float(\n",
        "            torch.sum(model.encoder_conv1.weight == 0)\n",
        "            + torch.sum(model.encoder_conv2.weight == 0)\n",
        "            + torch.sum(model.encoder_conv3.weight == 0)\n",
        "            + torch.sum(model.bridge_conv.weight == 0)\n",
        "            + torch.sum(model.decoder_conv1.weight == 0)\n",
        "            + torch.sum(model.decoder_conv2.weight == 0)\n",
        "            + torch.sum(model.decoder_conv3.weight == 0)\n",
        "            + torch.sum(model.output_conv.weight == 0)\n",
        "        )\n",
        "        / float(\n",
        "            model.encoder_conv1.weight.nelement()\n",
        "            + model.encoder_conv2.weight.nelement()\n",
        "            + model.encoder_conv3.weight.nelement()\n",
        "            + model.bridge_conv.weight.nelement()\n",
        "            + model.decoder_conv1.weight.nelement()\n",
        "            + model.decoder_conv2.weight.nelement()\n",
        "            + model.decoder_conv3.weight.nelement()\n",
        "            + model.output_conv.weight.nelement()\n",
        "        )\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNS9k2DwkYgs",
        "outputId": "943b703f-8abe-40f0-c18e-d1c42e64bc0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sparsity in conv1.weight: 1.39%\n",
            "Sparsity in conv2.weight: 9.07%\n",
            "Sparsity in fc1.weight: 12.72%\n",
            "Sparsity in fc2.weight: 17.99%\n",
            "Sparsity in fc3.weight: 25.47%\n",
            "Sparsity in fc3.weight: 18.06%\n",
            "Sparsity in fc3.weight: 12.87%\n",
            "Sparsity in fc3.weight: 2.50%\n",
            "Global sparsity: 20.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sparsity refers to the percentage of pruned weights (parameters) in a neural network. When pruning is applied to a model, a certain fraction of the weights are set to zero, effectively removing them from the network. The sparsity induced in pruned parameters is a measure of how much of the model's weights have been pruned or set to zero."
      ],
      "metadata": {
        "id": "De8j5i29ms1o"
      }
    }
  ]
}